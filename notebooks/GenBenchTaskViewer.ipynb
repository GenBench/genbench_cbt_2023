{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGNIn0Ay9sr0"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.sandbox.google.com/github/GenBench/genbench_cbt/blob/backend_dev/notebooks/GenBenchTaskViewer.ipynb)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title  ⚠️ **Run me first ⚠️ :** Execute this cell to perform some setup tasks (shift-Enter).  This may take several minutes.\n",
        "\n",
        "#@markdown If you'd like to load a different branch, replace the url below with the url of your branch. As an example if you want to interact with a task from a pull request that has a header \"**[user]** wants to merge 1 commit into `genbench:main` from `[account]:[branch_name]`\"\", then you should replace `genbench` with `[account]` and `main` with `[branch_name]` in the **genbench_branch** field below.\n",
        "\n",
        "\n",
        "genbench_branch = \"https://github.com/GenBench/genbench_cbt.git@backend_dev\" #@param {type:\"string\"}\n",
        "genbench_branch = genbench_branch.strip(\"/\")\n",
        "if \".git\" not in genbench_branch:\n",
        "  genbench_branch += \".git\"\n",
        "! pip install -q \"genbench[dev] @ git+$genbench_branch\" gradio\n",
        "\n",
        "\n",
        "import os\n",
        "\n",
        "from collections import defaultdict\n",
        "from pathlib import Path\n",
        "\n",
        "from genbench.utils.tasks import get_all_tasks_ids, get_all_task_metadata\n",
        "\n",
        "def get_keywords_to_task_ids():\n",
        "  metadata = get_all_task_metadata()\n",
        "  keywords_to_task_ids = defaultdict(list)\n",
        "  for task_id in sorted(metadata.keys()):\n",
        "    m = metadata[task_id]\n",
        "    for keyword in m[\"keywords\"]:\n",
        "      keywords_to_task_ids[keyword].append(task_id)\n",
        "\n",
        "    if \"subtasks\" in m:\n",
        "      for subtask_id in sorted(m.get(\"subtasks\", {}).keys()):\n",
        "        subtask_m = m[\"subtasks\"][subtask_id]\n",
        "        for keyword in subtask_m[\"keywords\"]:\n",
        "          keywords_to_task_ids[keyword].append(\n",
        "              f\"{task_id}:{subtask_id}\"\n",
        "          )\n",
        "\n",
        "  return keywords_to_task_ids\n",
        "\n",
        "def get_most_recent_task_ids():\n",
        "  from genbench import tasks\n",
        "\n",
        "  task_dirs = list(Path(tasks.__file__).parent.iterdir())\n",
        "  task_dirs = [\n",
        "    d\n",
        "    for d in task_dirs\n",
        "    if d.is_dir() and not d.name.startswith(\"__\")\n",
        "  ]\n",
        "  task_dirs.sort(\n",
        "      reverse=True,\n",
        "      key=lambda task_dir: os.path.getmtime(task_dir),\n",
        "  )\n",
        "  task_ids = [d.name for d in task_dirs]\n",
        "  return task_ids\n",
        "\n",
        "keywords_to_task_ids = get_keywords_to_task_ids()\n",
        "most_recent_task_ids = get_most_recent_task_ids()\n",
        "all_tasks_metadata = get_all_task_metadata()\n",
        "\n",
        "import numpy as np\n",
        "import gradio as gr\n",
        "\n",
        "intro_text = \"\"\"\\\n",
        "# GenBench Task Directory\n",
        "\n",
        "Some nice description\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "task_info = \"\"\"\\\n",
        "### {task_name} (`{task_id}`)\n",
        "{task_decription}\n",
        "#### Authors\n",
        "{task_authors}\n",
        "#### Keywords\n",
        "{task_keywords}\n",
        "\"\"\"\n",
        "\n",
        "def add_task(task_id):\n",
        "  if \":\" in task_id:\n",
        "    root_task_id, subtask_id = task_id.split(\":\")\n",
        "    metadata = all_tasks_metadata[root_task_id][\"subtasks\"][subtask_id]\n",
        "  else:\n",
        "    metadata = all_tasks_metadata[task_id]\n",
        "  with gr.Accordion(task_id, open=False):\n",
        "    gr.Markdown(task_info.format(\n",
        "        task_name=metadata[\"name\"],\n",
        "        task_id=task_id,\n",
        "        task_decription=metadata[\"description\"],\n",
        "        task_authors=\", \".join(metadata[\"authors\"]),\n",
        "        task_keywords=\", \".join(metadata[\"keywords\"])\n",
        "    ))\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "  gr.Markdown(intro_text)\n",
        "\n",
        "  with gr.Tab(\"Most Recent Tasks\"):\n",
        "    for task_id in most_recent_task_ids[:10]:\n",
        "      add_task(task_id)\n",
        "\n",
        "  for keyword in sorted(keywords_to_task_ids.keys()):\n",
        "    with gr.Tab(keyword):\n",
        "      for task_id in keywords_to_task_ids[keyword]:\n",
        "        add_task(task_id)\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "id": "86cgLGWZZyTf",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4tmmamqNWtI",
        "cellView": "form"
      },
      "source": [
        "#@title View Task\n",
        "#@markdown ⚠️  Run this cell launch the task viewer UI\n",
        "\n",
        "\n",
        "import datasets\n",
        "from random import choices\n",
        "from genbench.api import PreparationStrategy\n",
        "import gradio as gr\n",
        "import numpy as np\n",
        "\n",
        "def hide_elemnts(*elements):\n",
        "  return {\n",
        "      e: gr.update(visible=False)\n",
        "      for e in elements\n",
        "  }\n",
        "\n",
        "def show_elemnts(*elements):\n",
        "  return {\n",
        "      e: gr.update(visible=True)\n",
        "      for e in elements\n",
        "  }\n",
        "\n",
        "\n",
        "EXAMPLE_MARKDOWN_TEMPLATE = \"\"\"\\\n",
        "**Example ID:** {example_id}\n",
        "#### Input\n",
        "```\n",
        "{input}\n",
        "```\n",
        "#### Target\n",
        "```\n",
        "{target}\n",
        "```\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "MAX_NUM_EXAMPLES = 10\n",
        "\n",
        "with gr.Blocks(theme=gr.themes.Default(spacing_size=\"sm\")) as demo:\n",
        "  task_obj = [None]\n",
        "  gr.Markdown(\"# Task Viewer\\nSome nice description\")\n",
        "  with gr.Row().style(equal_height=True):\n",
        "    task_id = gr.Textbox(label=\"Task Id\", placeholder=\"<task_id>:<sub_task_id>\")\n",
        "    with gr.Column(scale=0):\n",
        "      fetch_btn = gr.Button(\"Load\", scale=0, variant=\"primary\")\n",
        "      clear_btn = gr.Button(\"Clear\",  scale=0)\n",
        "\n",
        "  loading_error = gr.Textbox(show_label=False, visible=False, container=False)\n",
        "\n",
        "  with gr.Box(visible=False) as task_metdata_box:\n",
        "    task_metadata = gr.Markdown()\n",
        "\n",
        "  prep_strategy_radio = gr.Radio(\n",
        "      [\"Finetuning\", \"Prompt-based Testing\"],\n",
        "      label=\"Preparation Strategy\",\n",
        "      info=\"The strategy to prepare the dataset for generalisation evaluation\",\n",
        "      visible=False\n",
        "  )\n",
        "  num_shots_slider = gr.Slider(\n",
        "      0, 20, value=0,\n",
        "      step=1,\n",
        "      label=\"Num Shots\",\n",
        "      info=\"Number of examplars in few-shot evaluation (0 means zero-shot learning)\",\n",
        "      visible=False\n",
        "  )\n",
        "  prep_btn = gr.Button(\"Prepare\", variant=\"primary\", visible=False)\n",
        "\n",
        "  dataset_split_selector = gr.Radio(\n",
        "      [\"Test\", \"Validation\", \"Train\"],\n",
        "      label=\"Dataset Split\",\n",
        "      visible=False,\n",
        "      interactive=False,\n",
        "  )\n",
        "\n",
        "  with gr.Row():\n",
        "    example_ids_input = gr.Textbox(\n",
        "        label=\"Example IDs\",\n",
        "        info=\"Specifiy the IDs of examples to show (separate with ','). Note that 0 <= id < dataset_len\",\n",
        "        visible=False\n",
        "    )\n",
        "    with gr.Column(scale=0):\n",
        "      show_example_btn = gr.Button(\"Show\", visible=False)\n",
        "      random_example_btn = gr.Button(\"Random\", visible=False)\n",
        "\n",
        "  example_md_lst = []\n",
        "  example_box_lst = []\n",
        "  for _ in range(MAX_NUM_EXAMPLES):\n",
        "    with gr.Box(visible=False) as examples_box:\n",
        "      example_md = gr.Markdown(visible=False)\n",
        "      example_md_lst.append(example_md)\n",
        "      example_box_lst.append(examples_box)\n",
        "\n",
        "  task_info_box = [task_metdata_box]\n",
        "  prep_box = [prep_strategy_radio, num_shots_slider, prep_btn]\n",
        "  show_example_box = [example_ids_input, show_example_btn, random_example_btn]\n",
        "  examples_box = [dataset_split_selector, *example_md_lst, *example_box_lst]\n",
        "\n",
        "  def fetch_task(task_id):\n",
        "    orig_task_id = task_id\n",
        "    if \":\" in task_id:\n",
        "      task_id, subtask_id = task_id.split(\":\")\n",
        "    else:\n",
        "      subtask_id = None\n",
        "\n",
        "    if (\n",
        "        (not task_id in all_tasks_metadata)\n",
        "        or (\"subtasks\" in all_tasks_metadata[task_id] and subtask_id not in all_tasks_metadata[\"subtasks\"][subtask_id])\n",
        "        or (\"subtasks\" not in all_tasks_metadata[task_id] and subtask_id is not None)\n",
        "    ):\n",
        "      return {\n",
        "          loading_error: gr.update(\n",
        "              value=f\"Task ID `{orig_task_id}` not found!\",\n",
        "              visible=True,\n",
        "          ),\n",
        "          # task_metdata_box: gr.update(visible=False),\n",
        "          **hide_elemnts(*task_info_box, *prep_box, *show_example_box, *examples_box)\n",
        "      }\n",
        "\n",
        "    if \"subtasks\" in all_tasks_metadata[task_id] and subtask_id is None:\n",
        "      return {\n",
        "          loading_error: gr.update(\n",
        "              value=(\n",
        "                  f\"Please specify the Subtask ID using `{orig_task_id}:<subtask_id>`.\"\n",
        "                  f\"\\n`{task_id}`'s subtasks: {sorted(all_tasks_metadata[task_id]['subtasks'].keys())}\"\n",
        "              ),\n",
        "              visible=True,\n",
        "          ),\n",
        "          # task_metdata_box: gr.update(visible=False),\n",
        "          **hide_elemnts(*task_info_box, *prep_box, *show_example_box, *examples_box)\n",
        "      }\n",
        "\n",
        "    if subtask_id is None:\n",
        "      metadata = all_tasks_metadata[task_id]\n",
        "    else:\n",
        "      metadata = all_tasks_metadata[task_id][\"subtasks\"][subtask_id]\n",
        "\n",
        "    from genbench import load_task\n",
        "\n",
        "    the_task = load_task(orig_task_id)\n",
        "    task_obj[0] = the_task\n",
        "\n",
        "    # Update Metadata Message\n",
        "    output_txt = task_info.format(\n",
        "        task_name=metadata[\"name\"],\n",
        "        task_id=task_id,\n",
        "        task_decription=metadata[\"description\"],\n",
        "        task_authors=\", \".join(metadata[\"authors\"]),\n",
        "        task_keywords=\", \".join(metadata[\"keywords\"])\n",
        "    )\n",
        "\n",
        "    # Update available Prep. Strategies\n",
        "    prep_strategies = []\n",
        "    show_num_shots_slider = False\n",
        "    if the_task.config.preparation_strategies is not None:\n",
        "      if the_task.config.preparation_strategies.finetuning is not None:\n",
        "        prep_strategies.append(PreparationStrategy.FINETUNING.value)\n",
        "      if the_task.config.preparation_strategies.prompt_based_testing is not None:\n",
        "        prep_strategies.append(PreparationStrategy.PROMPT_BASED_TESTING)\n",
        "        show_num_shots_slider = True\n",
        "    else:\n",
        "      prep_strategies = [\n",
        "          PreparationStrategy.FINETUNING.value,\n",
        "          PreparationStrategy.PROMPT_BASED_TESTING,\n",
        "      ]\n",
        "      show_num_shots_slider = True\n",
        "\n",
        "    if len(prep_strategies) == 0:\n",
        "      raise ValueError(\"The task does not support any preparation strategies.\")\n",
        "\n",
        "    return {\n",
        "        task_metadata: gr.update(value=output_txt),\n",
        "        task_metdata_box: gr.update(visible=True),\n",
        "\n",
        "        prep_strategy_radio: gr.update(choices=prep_strategies, value=prep_strategies[0],\n",
        "                                       visible=True, interactive=True),\n",
        "        num_shots_slider: gr.update(visible=show_num_shots_slider, interactive=True),\n",
        "        prep_btn: gr.update(visible=True),\n",
        "\n",
        "        # loading_error: gr.update(value=\"\", visible=False)\n",
        "        **hide_elemnts(loading_error, *show_example_box, *examples_box),\n",
        "    }\n",
        "\n",
        "  def render_examples(dataset, example_ids):\n",
        "    assert len(example_ids) <= MAX_NUM_EXAMPLES\n",
        "\n",
        "    updates = {}\n",
        "    for i, idx in enumerate(example_ids):\n",
        "      d = dataset[idx]\n",
        "      rendered_txt = EXAMPLE_MARKDOWN_TEMPLATE.format(\n",
        "          example_id=str(idx),\n",
        "          input=str(d[\"input\"]),\n",
        "          target=str(d[\"target\"])\n",
        "      )\n",
        "      updates[example_box_lst[i]] = gr.update(visible=True)\n",
        "      updates[example_md_lst[i]] = gr.update(value=rendered_txt, visible=True)\n",
        "\n",
        "    for i in range(len(example_ids), MAX_NUM_EXAMPLES):\n",
        "      updates[example_box_lst[i]] = gr.update(visible=False)\n",
        "      updates[example_md_lst[i]] = gr.update(visible=False)\n",
        "\n",
        "    return updates\n",
        "\n",
        "  def render_dataset(ds, split_options, split_option_choice_idx=0):\n",
        "    example_ids = rng.choice(\n",
        "        len(ds), min(MAX_NUM_EXAMPLES, len(ds)), replace=False\n",
        "    ).tolist()\n",
        "    return {\n",
        "          dataset_split_selector: gr.update(\n",
        "              choices=split_options,\n",
        "              visible=True,\n",
        "              value=split_options[split_option_choice_idx],\n",
        "              interactive=len(split_options) > 1,\n",
        "          ),\n",
        "          example_ids_input: gr.update(\n",
        "              value=\",\".join([str(i) for i in example_ids]),\n",
        "              interactive=True,\n",
        "              visible=True,\n",
        "          ),\n",
        "\n",
        "          **show_elemnts(show_example_btn, random_example_btn),\n",
        "          **render_examples(ds, example_ids),\n",
        "      }\n",
        "\n",
        "\n",
        "  loaded_dataset = [None, None, None]\n",
        "  rng = np.random.RandomState(seed=42)\n",
        "  def prepare_datasets(prep_strategy, num_shots):\n",
        "    # raise gr.Error(\"Cannot divide by zero!\")\n",
        "    # raise gr.exceptions.Error('some error')\n",
        "    prep_strategy = PreparationStrategy(prep_strategy)\n",
        "\n",
        "    task = task_obj[0]\n",
        "    if prep_strategy == PreparationStrategy.FINETUNING:\n",
        "      ds = task.get_prepared_datasets(prep_strategy)\n",
        "      split_options = [f\"{opt} (len={len(ds[opt.lower()])})\" for opt in [\"Test\", \"Validation\", \"Train\"] if opt in ds]\n",
        "      loaded_dataset[0] = ds\n",
        "      loaded_dataset[1] = ds[\"test\"]\n",
        "      loaded_dataset[2] = split_options[0]\n",
        "\n",
        "      return render_dataset(ds[\"test\"], split_options)\n",
        "\n",
        "    if prep_strategy == PreparationStrategy.PROMPT_BASED_TESTING:\n",
        "      ds = task.get_prepared_datasets(prep_strategy, shot_list=[num_shots])[num_shots]\n",
        "      split_options = [f\"Test (len={len(ds)})\"]\n",
        "      loaded_dataset[0] = ds\n",
        "      loaded_dataset[1] = ds\n",
        "      loaded_dataset[2] = split_options[0]\n",
        "\n",
        "      return render_dataset(ds, split_options)\n",
        "\n",
        "  def change_dataset_split(split):\n",
        "    split_name = split.split(\" \")[0].lower()\n",
        "    print(split_name)\n",
        "\n",
        "    if not isinstance(loaded_dataset[0], dict):\n",
        "      return render_dataset(loaded_dataset[1], [loaded_dataset[2]])\n",
        "    else:\n",
        "      ds = loaded_dataset[0]\n",
        "      split_options = [f\"{opt} (len={len(ds[opt.lower()])})\" for opt in [\"Test\", \"Validation\", \"Train\"] if opt in ds]\n",
        "      split_option_choice_idx = split_options.index(split)\n",
        "\n",
        "      loaded_dataset[1] = ds[split_name]\n",
        "      loaded_dataset[2] = split_options[split_option_choice_idx]\n",
        "\n",
        "      return render_dataset(\n",
        "          loaded_dataset[1],\n",
        "          split_options, split_option_choice_idx\n",
        "      )\n",
        "\n",
        "\n",
        "  def show_example(example_ids_str, is_random=False):\n",
        "    ds = loaded_dataset[1]\n",
        "    if is_random:\n",
        "      example_ids = rng.choice(\n",
        "          len(ds), min(MAX_NUM_EXAMPLES, len(ds)), replace=False\n",
        "      ).tolist()\n",
        "    else:\n",
        "      example_ids = [int(s.strip()) for s in example_ids_str.split(\",\")]\n",
        "\n",
        "    return {\n",
        "        example_ids_input: gr.update(\n",
        "              value=\",\".join([str(i) for i in example_ids]),\n",
        "              interactive=True,\n",
        "        ),\n",
        "        **render_examples(ds, example_ids)\n",
        "    }\n",
        "\n",
        "  def clear_ui():\n",
        "    return hide_elemnts(\n",
        "        loading_error,\n",
        "        *task_info_box,\n",
        "        *prep_box,\n",
        "        *show_example_box,\n",
        "        *examples_box\n",
        "    )\n",
        "\n",
        "\n",
        "  fetch_btn.click(\n",
        "      fetch_task,\n",
        "      inputs=task_id,\n",
        "      outputs=[\n",
        "          loading_error, task_metadata, task_metdata_box,\n",
        "          prep_strategy_radio, num_shots_slider, prep_btn,\n",
        "          *show_example_box, *examples_box\n",
        "      ]\n",
        "  )\n",
        "  clear_btn.click(\n",
        "      clear_ui,\n",
        "      outputs=[\n",
        "        loading_error,\n",
        "        *task_info_box,\n",
        "        *prep_box,\n",
        "        *show_example_box,\n",
        "        *examples_box\n",
        "      ]\n",
        "  )\n",
        "  prep_btn.click(\n",
        "      prepare_datasets,\n",
        "      inputs=[prep_strategy_radio, num_shots_slider],\n",
        "      outputs=[\n",
        "          dataset_split_selector,\n",
        "          example_ids_input, show_example_btn, random_example_btn,\n",
        "          *example_box_lst, *example_md_lst\n",
        "      ],\n",
        "      show_progress=True\n",
        "  )\n",
        "  show_example_btn.click(\n",
        "      lambda x: show_example(x),\n",
        "      inputs=example_ids_input,\n",
        "      outputs=[\n",
        "          example_ids_input,\n",
        "          *example_box_lst, *example_md_lst\n",
        "      ],\n",
        "      show_progress=True\n",
        "  )\n",
        "  random_example_btn.click(\n",
        "      lambda: show_example(None, is_random=True),\n",
        "      inputs=None,\n",
        "      outputs=[\n",
        "          example_ids_input,\n",
        "          *example_box_lst, *example_md_lst\n",
        "      ],\n",
        "      show_progress=True\n",
        "  )\n",
        "  dataset_split_selector.change(\n",
        "      change_dataset_split,\n",
        "      inputs=dataset_split_selector,\n",
        "      outputs=[\n",
        "          dataset_split_selector,\n",
        "          example_ids_input, show_example_btn, random_example_btn,\n",
        "          *example_box_lst, *example_md_lst\n",
        "      ],\n",
        "      show_progress=True\n",
        "  )\n",
        "\n",
        "\n",
        "demo.launch(height=900)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}